{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsGspc6lJIxo",
        "outputId": "5abfca16-42ce-4dcd-fa24-5a7dbf5684d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSQT8h3CI37c"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/fine_tune_data1.json\"\n",
        "\n",
        "# Load the dataset\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)"
      ],
      "metadata": {
        "id": "vCxMeXV-JQ-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3303e8-3b88-4763-cb36-143b28d79910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples: 40\n",
            "First example:\n",
            "{'role': 'system', 'content': 'You are a friendly and polite guide who give the travel place information in Thailand.'}\n",
            "{'role': 'user', 'content': 'ชื่อสถานที่: วัดป่าตึง\\n\\nประเภท สถานที่ท่องเที่ยววัด\\n\\nข้อมูลรายละเอียดสถานที่: '}\n",
            "{'role': 'assistant', 'content': 'หลวงปู่หล้า ตาทิพย์ วัดป่าตึง ตั้งอยู่ในเขตตำบลออนใต้ อำเภอสันกำแพง เดิมเป็นวัดร้าง คู่กับวัดเชียงแสน ก่อนที่จะสร้างวัดนี้ขึ้นมาได้พบพระบรมสารีริกธาตุ และของมีค่ามากมายหลายอย่าง ความน่าสนใจของวัดป่าตึง คือการเป็นวัดเก่าคู่กับวัดเชียงแสน แม้จะเป็นวัดร้างก็ตาม แต่ก็มีการค้นพบพระบรมสารีริกธาตุและของมีค่ามากมายหลายอย่าง อาทิ วัตถุโบราณ พระพุทธรูป เครื่องถ้วยชามสังคโลก ซึ่งปัจจุบันเก็บอยู่ในพิพิธภัณฑ์เครื่องถ้วยชามที่ตั้งอยู่ภายในบริเวณวัด นอกจากนี้ภายในศาลาการเปรียญยังเป็นที่ตั้งศพของเกจิอาจารย์ชื่อดัง คือหลวงปู่หล้า ซึ่งสังขารของท่านไม่เน่าเปื่อยให้ผู้ที่มีศรัทธาได้บูชา ในขณะที่ท่านมีชีวิตอยู่นั้น ท่านได้รับสมญานามจากศรัทธาญาติโยมว่าเป็นพระภิกษุที่มีญาณวิเศษ ที่สามารถล่วงรู้เหตุการณ์ในอนาคตได้ หลายคนจึงขนานนามท่านว่า หลวงปู่หล้า ตาทิพย์ ท่านเป็นพระเกจิอีกรูปหนึ่งที่ปฏิบัติดี ปฏิบัติชอบ ตั้งตนอยู่ในหลักศีลธรรมอันงดงามมาโดยตลอด หลวงปู่หล้า หรือพระครูจันทสมานคุณ นั้น เกิดในรัชสมัยของพระบาทสมเด็จพระพุทธเจ้าหลวง รัชกาลที่ 5 ซึ่งอยู่ในช่วงผลัดเปลี่ยนเจ้าผู้ครองนครเชียงใหม่ สมัยของเจ้าอินทวิชยานนท์ เจ้าผู้ครองนครเชียงใหม่องค์ที่ 7 (พ.ศ. 2426-2439) กับเจ้าอินทวโรรสสุริยวงศ์ เจ้าผู้ครองนครเชียงใหม่องค์ที่ 8 (พ.ศ. 2442-2452) โดยท่านเกิดเมื่อวันพฤหัสบดีที่ 22 กันยายน พ.ศ. 2441 ที่บ้านปง ตำบลออนใต้ อำเภอสันกำแพง จังหวัดเชียงใหม่ เมื่ออายุได้ 8 ขวบ โยมแม่ก็นำไปฝากกับครูบาปินตา เจ้าอาวาสวัดป่าตึง ท่านจึงได้มีโอกาสเรียนหนังสือเป็นครั้งแรก ซึ่งสมัยนั้นจะเรียนหนังสือพื้นเมืองจนอายุได้ 11 ขวบ ก็ได้บวชเป็นสามเณรในช่วงเข้ารุกขมูล และเข้ากรรมอยู่ในป่า การเข้ากรรมหรืออยู่กรรมนั้น เรียกว่าประเพณีเข้าโสสานกรรม ซึ่งเป็นประเพณีที่สำคัญอย่างหนึ่งของพระพุทธศาสนา ที่พระสงฆ์จะต้องถือปฏิบัติอย่างเคร่งครัด ซึ่งมักกระทำกันในบริเวณป่าช้าที่อยู่นอกวัด พระสงฆ์และผู้ที่เข้าบำเพ็ญโสสานกรรมจะต้องถือปฏิบัติเคร่งครัด เพื่อต้องการบรรเทากิเลสตัณหา เมื่ออายุได้ 18 ปี จึงเดินทางไปจำพรรษาอยู่ในเมืองเชียงใหม่เพื่อเรียนนักธรรมที่วัดเชตุพน เรียนได้ยังไม่ทันสำเร็จต้องกลับวัดป่าตึง เพื่อปรนนิบัติครูบาปินตาที่ชราภาพ จนกระทั่งปี พ.ศ. 2467 ครูบาปินตาก็มรณภาพด้วยวัย 74 ปี และหลวงปู่หล้าได้รับตำแหน่งเจ้าอาวาสวัดป่าตึงต่อจากครูบาปินตาแทน เมื่อปี พ.ศ. 2467 โดยท่านได้รับการแต่งตั้งสมณศักดิ์เป็นพระครูจันทสมานคุณ ซึ่งขณะนั้นมีอายุ 63 ปี และได้มรณภาพลงเมื่อวันที่ 16 กุมภาพันธ์ 2536 ในขณะที่มีอายุได้ 97 ปี ที่ตั้ง : ตั้งอยู่ในเขตตำบลออนใต้ อำเภอสันกำแพง จังหวัดเชียงใหม่'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        function_call = message.get(\"function_call\", None)\n",
        "\n",
        "        if (not content and not function_call) or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gknnNzIDJZeo",
        "outputId": "e0e4c4dd-78dd-4a4a-f81b-51a7b1475826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
      ],
      "metadata": {
        "id": "BDqOiuq_KGs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ_LSmL4KLg6",
        "outputId": "9646b068-74b0-456a-fc01-41e7466cd9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 480, 2425\n",
            "mean / median: 1274.125, 1217.5\n",
            "p5 / p95: 662.1, 1908.6000000000004\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 340, 2282\n",
            "mean / median: 1148.025, 1086.0\n",
            "p5 / p95: 549.8, 1765.6000000000004\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxMX03XvKj1A",
        "outputId": "61785c89-0848-4b0b-b4cd-9eff4c66c304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has ~50965 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~152895 tokens\n"
          ]
        }
      ]
    }
  ]
}